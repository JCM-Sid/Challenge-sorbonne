{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16312,"status":"ok","timestamp":1742994966616,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"vx1v6NiktSu7","outputId":"9fc125ff-3caf-4a58-9271-536d388255fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m61.4/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.14)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.6.1\n","device is cpu\n","The current working directory is: /content\n"]}],"source":["# Challenge Sorbonne - DST\n","#\n","#!pip install torch_geometric\n","\n","import numpy as np\n","import pandas as pd\n","import os\n","import time\n","import os\n","import json\n","#import rarfile\n","import networkx as nx\n","import io\n","import re\n","import random\n","import csv\n","from datetime import datetime\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import random_split, Subset\n","from torch.optim import AdamW\n","!pip install torch_geometric\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import GATConv, global_mean_pool\n","import networkx as nx\n","\n","from collections import defaultdict, Counter\n","\n","import matplotlib.pyplot as plt\n","import plotly.io as pio\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","import plotly.graph_objects as go\n","\n","from sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","import tqdm as notebook_tqdm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device is\", device)\n","\n","current_directory = os.getcwd()\n","print(f\"The current working directory is: {current_directory}\")\n","\n","#env_system = os.environ\n","#print(env_system)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18759,"status":"ok","timestamp":1742994988870,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"KaGZYw4ZtSu8","outputId":"3972c2f6-e1a6-4945-ab3e-8c82cf0ec802"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# for Google Colab only\n","if 'COLAB_RELEASE_TAG' in os.environ:\n","    from google.colab import drive\n","    drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"elapsed":838,"status":"ok","timestamp":1742995143971,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"eLIITiH84EOo","outputId":"3d29a151-3bad-42c9-aee5-94cc5d8faa90"},"outputs":[{"output_type":"stream","name":"stdout","text":["The current working directory is: /content\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                name  \\\n","0  9fbf213113ba0a18dc2642f83b1201541428fd7951d6a8...   \n","1  1b35c9dbf3cd9ac60015aaa6cd451c898defa6dac1ff43...   \n","2  bf8d307a136a936f7338c1f2eec773c4eb1c802cab77da...   \n","3  1e51933903f0358c0b635f863368eb15a61cd3442bc5bf...   \n","4  8a6503fe68d699f8a31531c157e9da931192cd7e3ec809...   \n","\n","   64-bit execution via heavens gate  64bits  PEB access  \\\n","0                                  0       1           0   \n","1                                  0       0           0   \n","2                                  0       0           0   \n","3                                  0       0           0   \n","4                                  0       0           0   \n","\n","   accept command line arguments  access the Windows event log  \\\n","0                              0                             0   \n","1                              0                             0   \n","2                              0                             0   \n","3                              0                             0   \n","4                              0                             0   \n","\n","   act as TCP client  allocate RW memory  allocate RWX memory  \\\n","0                  0                   0                    0   \n","1                  0                   0                    0   \n","2                  0                   0                    0   \n","3                  0                   0                    0   \n","4                  0                   0                    0   \n","\n","   allocate memory  ...  winzip  wise  worm  write and execute a file  \\\n","0                0  ...       0     0     0                         0   \n","1                0  ...       0     0     0                         0   \n","2                0  ...       0     0     0                         0   \n","3                0  ...       0     0     0                         0   \n","4                0  ...       0     0     0                         0   \n","\n","   write clipboard data  write file on Linux  write file on Windows  \\\n","0                     0                    0                      0   \n","1                     0                    0                      1   \n","2                     0                    0                      0   \n","3                     0                    0                      0   \n","4                     0                    0                      0   \n","\n","   write pipe  xorcrypt  yoda  \n","0           0         0     0  \n","1           0         0     0  \n","2           0         0     0  \n","3           0         0     0  \n","4           0         0     0  \n","\n","[5 rows x 454 columns]"],"text/html":["\n","  <div id=\"df-1bdd0b1c-506d-464a-87c7-5e10c673829c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>64-bit execution via heavens gate</th>\n","      <th>64bits</th>\n","      <th>PEB access</th>\n","      <th>accept command line arguments</th>\n","      <th>access the Windows event log</th>\n","      <th>act as TCP client</th>\n","      <th>allocate RW memory</th>\n","      <th>allocate RWX memory</th>\n","      <th>allocate memory</th>\n","      <th>...</th>\n","      <th>winzip</th>\n","      <th>wise</th>\n","      <th>worm</th>\n","      <th>write and execute a file</th>\n","      <th>write clipboard data</th>\n","      <th>write file on Linux</th>\n","      <th>write file on Windows</th>\n","      <th>write pipe</th>\n","      <th>xorcrypt</th>\n","      <th>yoda</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9fbf213113ba0a18dc2642f83b1201541428fd7951d6a8...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1b35c9dbf3cd9ac60015aaa6cd451c898defa6dac1ff43...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>bf8d307a136a936f7338c1f2eec773c4eb1c802cab77da...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1e51933903f0358c0b635f863368eb15a61cd3442bc5bf...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8a6503fe68d699f8a31531c157e9da931192cd7e3ec809...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 454 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bdd0b1c-506d-464a-87c7-5e10c673829c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1bdd0b1c-506d-464a-87c7-5e10c673829c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1bdd0b1c-506d-464a-87c7-5e10c673829c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7ac98ddc-c309-4fe7-a77c-13355a7a3d7e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ac98ddc-c309-4fe7-a77c-13355a7a3d7e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7ac98ddc-c309-4fe7-a77c-13355a7a3d7e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_meta_train"}},"metadata":{},"execution_count":12}],"source":["current_directory = os.getcwd()\n","print(f\"The current working directory is: {current_directory}\")\n","\n","# init du repertoire des données\n","if current_directory == '/content': # Google Colab\n","    training_path_dir =   '/content/drive/MyDrive/Sorbonne_Data_challenge/folder_training_set'\n","    test_path_dir =       '/content/drive/MyDrive/Sorbonne_Data_challenge/folder_test_set'\n","    train_meta_data =     '/content/drive/MyDrive/Sorbonne_Data_challenge/training_set_metadata.csv'\n","\n","    model_save_file =     '/content/drive/MyDrive/Colab Notebooks/Sorbonne-Challenge/model_sorbonne_weights.pth'\n","    file_split_training = '/content/drive/MyDrive/Colab Notebooks/Sorbonne-Challenge-v12/split_val-colab-v12.csv'\n","    split_char = '/'\n","\n","    test_init_file =        '/content/drive/MyDrive/Colab Notebooks/Sorbonne-Challenge/test_set_to_predict.csv'\n","    filename_test_results = '/content/drive/MyDrive/Colab Notebooks/Sorbonne-Challenge/test_prediction.csv'\n","    filename_trained =      '/content/drive/MyDrive/Colab Notebooks/Sorbonne-Challenge/list_hash_trained.csv'\n","\n","elif current_directory == r\"c:\\Users\\jch_m\\DocumentsPerso\\Centrale-IAC\\Cours\\Python-ML\\ProjectMaster\\Challenge-Sorbonne\": #PC1\n","    split_char = '\\\\'\n","\n","    #training_path_dir =   r\"D:\\ChallengeDST\\folder_training_set\"\n","    #training_path_dir =   r\"..\\..\\Data\\ChallengeSorbonne\\training\"\n","    #training_path_dir =   r\"..\\..\\Data\\ChallengeSorbonne\\training_s\"\n","    filename_trained = r\".\\list_hash_trained.csv\"\n","\n","    train_meta_data =  r'..\\..\\Data\\ChallengeSorbonne\\training_set_metadata.csv'\n","    file_split_training = r'.\\split_training-pc.csv'\n","\n","    #test_path_dir =   r\"D:\\ChallengeDST\\folder_training_set\\folder_training_set\"\n","    #test_path_dir = r\"..\\..\\Data\\ChallengeSorbonne\\training\"\n","    #test_path_dir = r\"G:\\Mon Drive\\Colab Notebooks\\Sorbonne-Challenge\"\n","    #test_init_file = r\".\\test_set_to_predict.csv\"\n","    #filename_test_results = r\".\\test_prediction.csv\"\n","\n","    model_save_file =  r'.\\model_sorbonne_weights.pth'\n","    #filename_test_results = r\".\\test_prediction.csv\"\n","\n","elif current_directory == r\"c:\\Users\\jch_m\\Documents Perso\\DevPython\\Challenge-sorbonne\": #PC2\n","    split_char = '\\\\'\n","\n","    #training_path_dir =   r\"D:\\ChallengeDST\\folder_training_set\"\n","    training_path_dir =   r\"..\\..\\Data\\ChallengeSorbonne\\training\"\n","    #training_path_dir =   r\"..\\..\\Data\\ChallengeSorbonne\\training_s\"\n","    filename_trained = r\".\\list_hash_trained.csv\"\n","\n","    train_meta_data =  'training_set_metadata.csv'\n","    file_split_training = r'.\\split_training-pc.csv'\n","\n","    #test_path_dir =   r\"D:\\ChallengeDST\\folder_training_set\\folder_training_set\"\n","    #test_path_dir = r\"..\\..\\Data\\ChallengeSorbonne\\training\"\n","    test_path_dir = r\"G:\\.shortcut-targets-by-id\\19Ls71oZUG1aa1uTMu1laH6Nt3qK5gSZK\\Sorbonne_Data_challenge\\folder_test_set\"\n","    test_init_file = \"test_set_to_predict.csv\"\n","    filename_test_results = \"test_prediction.csv\"\n","    model_save_file =  'model_sorbonne_weights.pth'\n","else:\n","    print(\"**** ERROR: init files names and directories not done - root directory and environment not identified\")\n","\n","\n","# read CSV input and save in df\n","df_meta_train = pd.read_csv(train_meta_data, sep=\";\")\n","df_meta_train.head()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1742995083637,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"wCU7s5ZbtSu9","outputId":"f90a395e-1598-4430-ec12-023d86f1c231"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 23102 entries, 0 to 23101\n","Columns: 454 entries, name to yoda\n","dtypes: int64(453), object(1)\n","memory usage: 80.0+ MB\n"]}],"source":["df_meta_train.info()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"elapsed":729,"status":"ok","timestamp":1742995088880,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"bOuNPC0iZACE","outputId":"3e8a7303-8f99-4b35-a6de-ec04819f534e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Sorbonne-Challenge/list_hash_trained.csv\n","taille : 18900\n"]},{"output_type":"execute_result","data":{"text/plain":["                                       files_trained\n","0                                      files_trained\n","1  861f2c5f07c9e1c7d24c2e34eb47ff3129cd39a2227a25...\n","2  793a1bda32069f37ba201167d90e8c16c004008c4fd467...\n","3  819d0b70a905ae5f8bef6c47423964359c2a90a168414f...\n","4  892e7b1463b98d6f5b41579c6b314de3a723af2c67d88f..."],"text/html":["\n","  <div id=\"df-c956154f-7694-43cc-994b-0f5a93f6f37b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>files_trained</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>files_trained</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>861f2c5f07c9e1c7d24c2e34eb47ff3129cd39a2227a25...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>793a1bda32069f37ba201167d90e8c16c004008c4fd467...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>819d0b70a905ae5f8bef6c47423964359c2a90a168414f...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>892e7b1463b98d6f5b41579c6b314de3a723af2c67d88f...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c956154f-7694-43cc-994b-0f5a93f6f37b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c956154f-7694-43cc-994b-0f5a93f6f37b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c956154f-7694-43cc-994b-0f5a93f6f37b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2c67c2a3-1e2f-4850-8ba4-ed58010fe97e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c67c2a3-1e2f-4850-8ba4-ed58010fe97e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2c67c2a3-1e2f-4850-8ba4-ed58010fe97e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_files_trained","summary":"{\n  \"name\": \"df_files_trained\",\n  \"rows\": 18900,\n  \"fields\": [\n    {\n      \"column\": \"files_trained\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18900,\n        \"samples\": [\n          \"d205b2c163e78ab42a5d67d7664ef6b75ea0374ff0924467d624f9db0611f0ad\",\n          \"564aa833761b7b3f84daaec0e9ee9728b8f6db9c2f40cadef6f92e33dc92a2ab\",\n          \"ae715e12f54acefc1d30d2c94ae0288e725ca2de464e859bcc4cf060dff46de6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}],"source":["print(filename_trained)\n","df_files_trained = pd.read_csv(filename_trained, sep=\",\")\n","print(\"taille :\",len(df_files_trained))\n","df_files_trained.head()\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1742995476399,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"oRBCbVPaOKjz","outputId":"864f8ce9-421f-4a0c-cd1f-b51c6c97c2b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["['rep_0' 'rep_500']\n","['/content/drive/MyDrive/Sorbonne_Data_challenge/folder_training_set/40936a67037f8fd8e215b045f9cdf9c55840411316a62c85c8b54f75c6b0a5c8.json', '/content/drive/MyDrive/Sorbonne_Data_challenge/folder_training_set/368d2b5ccfd49f01942f462037710146ec3ca5ca8a5318a092bc49bfebfe8bad.json', '/content/drive/MyDrive/Sorbonne_Data_challenge/folder_training_set/75010f6d21b0b4451b5465ab8f46b385bb1edc15ed50634f4120352edc49cf3a.json', '/content/drive/MyDrive/Sorbonne_Data_challenge/folder_training_set/95e944577e686782e9d725e2e79ef9657a3f3b4f3b9cb265487bcd8e55cba95d.json', '/content/drive/MyDrive/Sorbonne_Data_challenge/folder_training_set/72356f26be98c580e23ca7baebe665c781fb2484575b9b05ad38676ad74ffb9e.json']\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 453 entries, 0 to 452\n","Data columns (total 2 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   orign path  453 non-null    object\n"," 1   batch       453 non-null    object\n","dtypes: object(2)\n","memory usage: 7.2+ KB\n","None\n"]}],"source":["# load & check traing split\n","df_training_split = pd.read_csv(file_split_training, sep=\",\")\n","full_file_list = df_training_split[df_training_split['batch'] == 'rep_0']['orign path'].tolist()\n","print(df_training_split['batch'].unique())\n","print(full_file_list[:5])\n","print(df_training_split.info())\n"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1742995606261,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"_gU6S_PgtSu9"},"outputs":[],"source":["def process_graph_directory(file_directory, val_size=0.1, rep_batch='rep_0', max_file=0):\n","    \"\"\"\n","    Scan the training directory\n","    get the hash name of the files, check and exclude hash file with error\n","    retour a list of hash for training, validation and error\n","    \"\"\"\n","\n","    list_train_hash, list_val_hash, list_err_hash  = [], [], []\n","    file_with_err = 0\n","    count_files = 0\n","    #max_file = 0\n","\n","    #file_split_training = r\"C:\\Users\\jch_m\\DocumentsPerso\\Centrale-IAC\\Cours\\Python-ML\\ProjectMaster\\ChallengeSorbonne\\split_training-colab.csv\"\n","    df_files_trained = pd.read_csv(filename_trained, sep=\",\")\n","    df_training_split = pd.read_csv(file_split_training, sep=\",\")\n","    full_file_list = df_training_split[df_training_split['batch']== rep_batch]['orign path'].tolist()\n","\n","    for full_path_file in full_file_list:\n","        # test if filename in the trained list\n","        hash_name = full_path_file.split('.jso')[0]\n","        hash_name = hash_name.split(split_char)[-1]\n","\n","        # file already trained\n","        if hash_name in df_files_trained['files_trained'].values:\n","        #    print(\"trained\")\n","            continue\n","\n","        # files not in metadata\n","        if hash_name not in df_meta_train['name'].values:\n","            list_err_hash.append(full_path_file)\n","            print(\"meta\", hash_name, full_path_file)\n","            continue\n","\n","        if os.path.exists(full_path_file):\n","            file_size = os.path.getsize(full_path_file)\n","            if file_size/1000 > 200_000: #file too big\n","                list_err_hash.append(full_path_file)\n","                print(\"size\", file_size/1000, full_path_file)\n","                continue\n","        else:\n","            list_err_hash.append(full_path_file)\n","            print(\"not exist\", full_path_file)\n","            continue\n","\n","        # check if nb of files is within the max_files allowed\n","        if max_file != 0 and count_files > max_file:\n","            list_err_hash.append(full_path_file)\n","            print(\"count\")\n","            break\n","\n","        list_val_hash.append(full_path_file)\n","        \"\"\"\n","        if count_files % (val_size*100) == 0:\n","            list_val_hash.append(full_path_file)\n","        else:\n","            list_train_hash.append(full_path_file)\n","\n","        count_files += 1\n","        \"\"\"\n","    print(f\"Number of files with error: {len(list_err_hash)}\")\n","    return list_train_hash, list_val_hash, list_err_hash"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"84w6HNzrOKjz","outputId":"bca9b4b0-03c1-45ba-d968-2873979f2cb4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742995610025,"user_tz":-60,"elapsed":264,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of files with error: 0\n","51 0 0\n"]}],"source":["list_train, list_val, list_err = process_graph_directory(training_path_dir, val_size=0.01, rep_batch='rep_0')\n","print(len(list_val), len(list_train), len(list_err))"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1742995613755,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"RLwlVa-5tSu9"},"outputs":[],"source":["class HierarchicalAssemblyTokenizer:\n","    def __init__(self):\n","        # Tokenizer implementation from previous code\n","        # Abbreviated for brevity but would be the full implementation\n","        self.node_type_vocab = {}\n","        self.operation_vocab = {}\n","        self.register_vocab = {}\n","        self.memory_pattern_vocab = {}\n","        self.immediate_vocab = {}\n","        self.UNK_TOKEN = \"<UNK>\"\n","\n","        # Regex patterns for parsing\n","        self.patterns = {\n","            'node_type': re.compile(r'([A-Z]+)\\s*:'),\n","            'operation': re.compile(r':\\s*([a-z]+)'),\n","            'registers': re.compile(r'(?:^|\\s+)([a-z]{2,3}x|[a-z]{2,3}i|[a-z]{1,3}h|[a-z]{1,3}l)(?:$|\\s+|,|\\])'),\n","            'memory_ref': re.compile(r'\\[(.*?)\\]'),\n","            'immediate': re.compile(r'0x[0-9a-fA-F]+|\\d+')\n","        }\n","\n","    def fit(self, graph_l, min_freq=1):\n","        \"\"\"Build vocabularies from the digraph nodes\"\"\"\n","        node_types = []\n","        operations = []\n","        registers = []\n","        memory_patterns = []\n","        immediates = []\n","        self.unique_hashes = []\n","        self.hash_to_id = {}\n","        self.id_to_hash = {}\n","\n","        # Extract features from node labels\n","        for item in graph_l:\n","            graph = item['graph_input']\n","            for node_id, node_attr in graph.nodes(data=True):\n","                label = node_attr.get('label', '')\n","\n","                # Extract node type (JCC, INST)\n","                node_type_match = self.patterns['node_type'].search(label)\n","                if node_type_match:\n","                    node_types.append(node_type_match.group(1))\n","\n","                # Extract operation (xor, push, mov)\n","                op_match = self.patterns['operation'].search(label)\n","                if op_match:\n","                    operations.append(op_match.group(1))\n","\n","                # Extract registers\n","                reg_matches = self.patterns['registers'].findall(label)\n","                registers.extend(reg_matches)\n","\n","                # Extract memory reference patterns\n","                mem_matches = self.patterns['memory_ref'].findall(label)\n","                for mem in mem_matches:\n","                    # Convert memory reference to a pattern (e.g., \"reg + offset\")\n","                    pattern = self._memory_to_pattern(mem)\n","                    memory_patterns.append(pattern)\n","\n","                # Extract immediate values\n","                imm_matches = self.patterns['immediate'].findall(label)\n","                immediates.extend(imm_matches)\n","\n","            self.unique_hashes.append(item['name'])\n","            self.unique_hashes = sorted(list(self.unique_hashes))\n","            for i, hash_val in enumerate(self.unique_hashes):\n","                self.hash_to_id[hash_val] = i\n","                self.id_to_hash[i] = hash_val\n","\n","        # Build vocabularies with frequency filtering\n","        self._build_vocab(self.node_type_vocab, node_types, min_freq)\n","        self._build_vocab(self.operation_vocab, operations, min_freq)\n","        self._build_vocab(self.register_vocab, registers, min_freq)\n","        self._build_vocab(self.memory_pattern_vocab, memory_patterns, min_freq)\n","        self._build_vocab(self.immediate_vocab, immediates, min_freq)\n","\n","        return self\n","\n","    def fit_from_counts(self, all_counts, min_freq=3):\n","        \"\"\"Fits the tokenizer from accumulated counts.\"\"\"\n","        self.node_type_vocab.clear()\n","        self.operation_vocab.clear()\n","        self.register_vocab.clear()\n","        self.memory_pattern_vocab.clear()\n","        self.immediate_vocab.clear()\n","\n","        self._build_vocab(self.node_type_vocab, all_counts['node_types'], min_freq)\n","        self._build_vocab(self.operation_vocab, all_counts['operations'], min_freq*2)\n","        self._build_vocab(self.register_vocab, all_counts['registers'], min_freq)\n","        self._build_vocab(self.memory_pattern_vocab, all_counts['memory_patterns'], min_freq*3)\n","        self._build_vocab(self.immediate_vocab, all_counts['immediates'], min_freq*3)\n","\n","        self.unique_hashes = all_counts['unique_hashes']\n","        self.unique_hashes = sorted(list(self.unique_hashes))\n","        for i, hash_val in enumerate(self.unique_hashes):\n","            self.hash_to_id[hash_val] = i\n","            self.id_to_hash[i] = hash_val\n","\n","    def _build_vocab(self, vocab_dict, tokens, min_freq):\n","        \"\"\"Build vocabulary with frequency filtering\"\"\"\n","        counter = Counter(tokens)\n","        # Add special UNK token\n","        vocab_dict[self.UNK_TOKEN] = 0\n","\n","        # Add tokens that meet minimum frequency\n","        idx = 1\n","        for token, count in counter.most_common():\n","            if count >= min_freq:\n","                vocab_dict[token] = idx\n","                idx += 1\n","\n","    def _memory_to_pattern(self, mem_ref):\n","        \"\"\"Convert memory reference to pattern\"\"\"\n","        # Replace registers with REG placeholder\n","        pattern = re.sub(r'[a-z]{2,3}x|[a-z]{2,3}i|[a-z]{1,3}h|[a-z]{1,3}l', 'REG', mem_ref)\n","        # Replace immediate values with IMM placeholder\n","        pattern = re.sub(r'0x[0-9a-fA-F]+|\\d+', 'IMM', pattern)\n","        return pattern.strip()\n","\n","    def tokenize(self, node_label):\n","        \"\"\"Tokenize a node label into hierarchical features\"\"\"\n","        features = {\n","            'node_type': self.UNK_TOKEN,\n","            'operation': self.UNK_TOKEN,\n","            'registers': [],\n","            'memory_pattern': self.UNK_TOKEN,\n","            'immediate': self.UNK_TOKEN\n","        }\n","\n","        # Extract node type\n","        node_type_match = self.patterns['node_type'].search(node_label)\n","        if node_type_match:\n","            node_type = node_type_match.group(1)\n","            features['node_type'] = node_type if node_type in self.node_type_vocab else self.UNK_TOKEN\n","\n","        # Extract operation\n","        op_match = self.patterns['operation'].search(node_label)\n","        if op_match:\n","            operation = op_match.group(1)\n","            features['operation'] = operation if operation in self.operation_vocab else self.UNK_TOKEN\n","\n","        # Extract registers\n","        reg_matches = self.patterns['registers'].findall(node_label)\n","        features['registers'] = [reg if reg in self.register_vocab else self.UNK_TOKEN for reg in reg_matches]\n","\n","        # Extract memory reference\n","        mem_matches = self.patterns['memory_ref'].findall(node_label)\n","        if mem_matches:\n","            pattern = self._memory_to_pattern(mem_matches[0])\n","            features['memory_pattern'] = pattern if pattern in self.memory_pattern_vocab else self.UNK_TOKEN\n","\n","        # Extract immediate values\n","        imm_matches = self.patterns['immediate'].findall(node_label)\n","        if imm_matches:\n","            imm = imm_matches[0]\n","            features['immediate'] = imm if imm in self.immediate_vocab else self.UNK_TOKEN\n","\n","        return features\n","\n","    def encode_nodelabel(self, node_label):\n","        \"\"\"Convert a node label to numeric feature vectors\"\"\"\n","        features = self.tokenize(node_label)\n","\n","        # Encode each feature\n","        node_type_idx = self.node_type_vocab.get(features['node_type'], self.node_type_vocab[self.UNK_TOKEN])\n","        operation_idx = self.operation_vocab.get(features['operation'], self.operation_vocab[self.UNK_TOKEN])\n","\n","        # Encode registers (take up to 3, pad if fewer)\n","        register_indices = []\n","        for i in range(min(3, len(features['registers']))):\n","            reg = features['registers'][i]\n","            reg_idx = self.register_vocab.get(reg, self.register_vocab[self.UNK_TOKEN])\n","            register_indices.append(reg_idx)\n","\n","        # Pad register indices if needed\n","        while len(register_indices) < 3:\n","            register_indices.append(0)  # 0 for padding\n","\n","        memory_pattern_idx = self.memory_pattern_vocab.get(\n","            features['memory_pattern'],\n","            self.memory_pattern_vocab[self.UNK_TOKEN]\n","        )\n","\n","        immediate_idx = self.immediate_vocab.get(\n","            features['immediate'],\n","            self.immediate_vocab[self.UNK_TOKEN]\n","        )\n","\n","        # Combine all indices into a feature vector\n","        encoded = np.array([\n","            node_type_idx,\n","            operation_idx,\n","            register_indices[0],\n","            register_indices[1],\n","            register_indices[2],\n","            memory_pattern_idx,\n","            immediate_idx\n","        ], dtype=np.int64)\n","\n","        return encoded\n","\n","    def encode_graph(self, digraph):\n","        \"\"\"Convert an entire digraph to node feature vectors\"\"\"\n","        node_features = {}\n","\n","        for node_id in digraph.nodes():\n","            label = digraph.nodes[node_id].get('label', '')\n","            node_features[node_id] = self.encode_nodelabel(label)\n","\n","        return node_features\n","\n","    def encode_hash(self, hash_file):\n","        return self.hash_to_id.get(hash_file, -1) # Return -1 if hash is not found\n","\n","    def get_vocab_sizes(self):\n","        \"\"\"Return the size of each vocabulary\"\"\"\n","        return {\n","            'node_type': len(self.node_type_vocab),\n","            'operation': len(self.operation_vocab),\n","            'register': len(self.register_vocab),\n","            'memory_pattern': len(self.memory_pattern_vocab),\n","            'immediate': len(self.immediate_vocab)\n","        }\n","\n","    def get_tokens_and_counts(self, graph_l):\n","        \"\"\"Extracts tokens and counts from graph_l.\"\"\"\n","        node_types = []\n","        operations = []\n","        registers = []\n","        memory_patterns = []\n","        immediates = []\n","        unique_hashes = []\n","        self.hash_to_id = {}\n","        self.id_to_hash = {}\n","\n","        for item in graph_l:\n","            graph = item['graph_input']\n","            for node_id, node_attr in graph.nodes(data=True):\n","                label = node_attr.get('label', '')\n","\n","                node_type_match = self.patterns['node_type'].search(label)\n","                if node_type_match:\n","                    node_types.append(node_type_match.group(1))\n","\n","                op_match = self.patterns['operation'].search(label)\n","                if op_match:\n","                    operations.append(op_match.group(1))\n","\n","                reg_matches = self.patterns['registers'].findall(label)\n","                registers.extend(reg_matches)\n","\n","                mem_matches = self.patterns['memory_ref'].findall(label)\n","                for mem in mem_matches:\n","                    pattern = self._memory_to_pattern(mem)\n","                    memory_patterns.append(pattern)\n","\n","                imm_matches = self.patterns['immediate'].findall(label)\n","                immediates.extend(imm_matches)\n","\n","            unique_hashes.append(item['name'])\n","\n","        return {\n","            'node_types': node_types,\n","            'operations': operations,\n","            'registers': registers,\n","            'memory_patterns': memory_patterns,\n","            'immediates': immediates,\n","            'unique_hashes': unique_hashes,\n","        }\n","\n","class AssemblyGraphDataset:\n","    def __init__(self, graph_list, tokenizer, node_feature_dim=60):\n","        \"\"\"\n","        Prepares a dataset of assembly graphs for GAT model training\n","        Args:\n","            graph_list: List of NetworkX digraphs representing assembly code\n","            tokenizer: HierarchicalAssemblyTokenizer instance\n","            node_feature_dim: Dimension of node embeddings\n","        \"\"\"\n","        self.graph_list = graph_list\n","        self.tokenizer = tokenizer\n","        self.node_feature_dim = node_feature_dim\n","\n","        # Initialize embedding layers for each feature type\n","        num_feature_type = 5\n","        vocab_sizes = tokenizer.get_vocab_sizes()\n","        self.node_type_embedding = nn.Embedding(vocab_sizes['node_type'], node_feature_dim // num_feature_type)\n","        self.operation_embedding = nn.Embedding(vocab_sizes['operation'], node_feature_dim // num_feature_type)\n","        self.register_embedding = nn.Embedding(vocab_sizes['register'], node_feature_dim // num_feature_type)\n","        self.memory_pattern_embedding = nn.Embedding(vocab_sizes['memory_pattern'], node_feature_dim // num_feature_type)\n","        self.immediate_embedding = nn.Embedding(vocab_sizes['immediate'], node_feature_dim // num_feature_type)\n","\n","        # Process graphs into PyTorch Geometric Data objects\n","        self.data_list = []\n","        for graph in self.graph_list:\n","            # process graph info\n","            self.data_list.append(self._process_graph(graph['graph_input'],graph['name']))\n","\n","    def _process_graph(self, graph, hash_name):\n","        \"\"\"Convert a NetworkX graph to a PyTorch Geometric Data object\"\"\"\n","        # Create a node ID mapping for consecutive IDs\n","        node_mapping = {node: i for i, node in enumerate(graph.nodes())}\n","\n","        # Get node features\n","        node_features_dict = self.tokenizer.encode_graph(graph)\n","\n","        # Convert to tensor-friendly format\n","        x = torch.zeros((len(graph.nodes()), 7), dtype=torch.long)\n","        for node_id, features in node_features_dict.items():\n","            x[node_mapping[node_id]] = torch.tensor(features)\n","\n","        # Create edge index\n","        edge_list = list(graph.edges())\n","        if not edge_list:\n","            # Handle case with no edges\n","            edge_index = torch.zeros((2, 0), dtype=torch.long)\n","        else:\n","            edge_index = self.optimize_edge_index(edge_list, node_mapping)\n","\n","        # Endcode Hash name\n","        encoded_hash = self.tokenizer.encode_hash(hash_name)\n","        encoded_hash_tensor = torch.tensor(encoded_hash, dtype=torch.long)\n","\n","        # Get embeddings before creating Data object\n","        x = self.get_embeddings(x)\n","\n","        # Create Data object\n","        data = Data(x=x, edge_index=edge_index, hash_encoded=encoded_hash_tensor)\n","        return data\n","\n","    def optimize_edge_index(self, edge_list, node_mapping):\n","        \"\"\"\n","        Optimizes the creation of edge_index tensor for graph representation.\n","        Args:\n","            edge_list (list of tuples): List of edge tuples (src, tgt).\n","            node_mapping (dict): Dictionary mapping node IDs to integer indices.\n","        Returns:\n","            torch.Tensor: Optimized edge_index tensor.\n","        \"\"\"\n","        if not edge_list:\n","            return torch.zeros((2, 0), dtype=torch.long)\n","\n","        num_edges = len(edge_list)\n","        src_indices = torch.empty(num_edges, dtype=torch.long)\n","        tgt_indices = torch.empty(num_edges, dtype=torch.long)\n","\n","        for i, (src, tgt) in enumerate(edge_list):\n","            src_indices[i] = node_mapping[src]\n","            tgt_indices[i] = node_mapping[tgt]\n","\n","        return torch.stack((src_indices, tgt_indices), dim=0).contiguous()\n","\n","    def __len__(self):\n","        return len(self.data_list)\n","\n","    def __getitem__(self, idx):\n","        return self.data_list[idx]\n","\n","    def get_embeddings(self, x):\n","        \"\"\"Transform tokenized features into embeddings\"\"\"\n","        # Split features into their components\n","        node_type_idx = x[:, 0]\n","        operation_idx = x[:, 1]\n","        register_idx1 = x[:, 2]\n","        register_idx2 = x[:, 3]\n","        register_idx3 = x[:, 4]\n","        memory_pattern_idx = x[:, 5]\n","        immediate_idx = x[:, 6]\n","\n","        # Get embeddings for each component\n","        node_type_emb = self.node_type_embedding(node_type_idx)\n","        operation_emb = self.operation_embedding(operation_idx)\n","\n","        # Combine register embeddings (average them)\n","        register_emb = (self.register_embedding(register_idx1) +\n","                        self.register_embedding(register_idx2) +\n","                        self.register_embedding(register_idx3)) / 3\n","\n","        memory_pattern_emb = self.memory_pattern_embedding(memory_pattern_idx)\n","        immediate_emb = self.immediate_embedding(immediate_idx)\n","\n","        # Concatenate all embeddings\n","        return torch.cat([\n","            node_type_emb,\n","            operation_emb,\n","            register_emb,\n","            memory_pattern_emb,\n","            immediate_emb\n","        ], dim=1)\n","\n","\"\"\"\n","Graph Attention Network for assembly code analysis\n","Args:\n","    dataset: AssemblyGraphDataset instance\n","    hidden_dim: Hidden dimension of GAT layers\n","    output_dim: Output dimension of node embeddings\n","    heads: Number of attention heads\n","    dropout: Dropout rate\n","\"\"\"\n","class AssemblyGAT(nn.Module):\n","    def __init__(self, node_feature_dim, hidden_dim=64, output_dim=453, heads=8, dropout=0.6, hash_dim=512):\n","        super(AssemblyGAT, self).__init__()\n","        self.conv1 = GATConv(node_feature_dim, hidden_dim, heads=heads, dropout=dropout)\n","        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=dropout)\n","        self.dropout = dropout\n","        self.hash_linear = nn.Linear(hash_dim, node_feature_dim) # Linear layer for hash encoding, adjusted dim\n","        self.hash_dim = hash_dim\n","\n","    def forward(self, x, edge_index, hash_encoded, batch):\n","        \"\"\"Forward pass through the GAT model\"\"\"\n","        # First GAT layer with activation and dropout\n","        x = F.elu(self.conv1(x, edge_index))\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","\n","        # Second GAT layer\n","        x = self.conv2(x, edge_index)\n","        x = global_mean_pool(x, batch)\n","        return x\n","\n","# Function to parse digraph string (as in previous example)\n","def parse_digraph_string(digraph_str):\n","    \"\"\"Parse the digraph string to create a NetworkX DiGraph\"\"\"\n","    # Simple parser for the provided format\n","    G = nx.DiGraph()\n","\n","    # Regular expressions for node and edge definitions\n","    node_pattern = re.compile(r'\"([^\"]+)\"\\s*\\[label\\s*=\\s*\"([^\"]+)\"\\]')\n","    edge_pattern = re.compile(r'\"([^\"]+)\"\\s*->\\s*\"([^\"]+)\"')\n","\n","    # Extract nodes and edges\n","    for line in digraph_str.strip().split('\\n'):\n","        line = line.strip()\n","\n","        # Skip the Digraph G { and } lines\n","        if line == 'Digraph G {' or line == '}':\n","            continue\n","\n","        # Parse node definitions\n","        node_match = node_pattern.search(line)\n","        if node_match:\n","            node_id = node_match.group(1)\n","            label = node_match.group(2)\n","            G.add_node(node_id, label=label)\n","            continue\n","\n","        # Parse edge definitions\n","        edge_match = edge_pattern.search(line)\n","        if edge_match:\n","            source = edge_match.group(1)\n","            target = edge_match.group(2)\n","            G.add_edge(source, target)\n","    return G"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":68,"status":"ok","timestamp":1742995627385,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"INiZZqldtSu-"},"outputs":[],"source":["# Create empty list to store dataframes\n","# init parameters to loop the file loading by batch\n","files_meta_list = set(df_meta_train['name'].astype(str))\n","random_seed = 42\n","\n","def process_batch(file_batch):\n","    \"\"\"\n","    Processes a batch of files.\n","    Args:\n","        file_batch (list): A list of file paths.\n","    \"\"\"\n","    graph_list_curr = []\n","    file_with_err = 0\n","\n","    for full_path_file in file_batch:\n","        try:\n","            with open(full_path_file, 'r') as f:\n","                hash_file = full_path_file.split('.jso')[0]\n","                hash_file = hash_file.split(split_char)[-1]\n","\n","                #f = open(full_path_file, 'r')\n","                digraph_str = f.read()\n","\n","                # test if file content has no error tag\n","                if 'ERROR' in digraph_str:\n","                    file_with_err += 1\n","                    continue\n","\n","                G = parse_digraph_string(digraph_str)\n","                graph_list_curr.append({\n","                    'name': hash_file,\n","                    'graph_input' : G\n","                })\n","                f.close()\n","\n","        except FileNotFoundError:\n","            print(f\"Error: File not found: {full_path_file}\")\n","        except Exception as e:\n","            print(f\"Error processing {full_path_file}: {e}\")\n","\n","    return graph_list_curr\n","\n","def get_metadata_from_hash(hash_list):\n","    hash_meta_values = []\n","    for hash_name in hash_list:\n","        df_y_values = df_meta_train[df_meta_train['name'] == hash_name].copy()\n","        df_y_values.drop(columns=['name'], inplace=True)\n","        if len(df_y_values) > 0 :\n","             hash_meta_values.append(df_y_values.values[0]) # Get the first row's values\n","        else:\n","            print(f\"{hash_name} not found in metadata\")\n","    return hash_meta_values\n","\n","def train_model(train_dataloader, train_hash, batch_size, epochs):\n","    if os.path.exists(model_save_file):\n","      if torch.cuda.is_available():\n","          model.load_state_dict(torch.load(model_save_file, weights_only=True))\n","      else:\n","          model.load_state_dict(torch.load(model_save_file, weights_only=True, map_location=torch.device('cpu')))\n","\n","    model.train()\n","    for epoch in range(epochs):\n","        train_loss = 0.0\n","        count_batch = 0\n","\n","        for batch in train_dataloader:\n","            optimizer.zero_grad()  # Zero gradients\n","\n","            # get the different components of the dataset\n","            x = batch.x.to(device)\n","            edge_index = batch.edge_index.to(device)\n","            hash_encoded = batch.hash_encoded.to(device)\n","            #print(f\"batch: {count_batch}  == x: {x.shape} edge_index: {edge_index.shape} \")\n","            list_hash_batch = train_hash[count_batch*batch_size:(count_batch+1)*batch_size]\n","            y_label = get_metadata_from_hash(list_hash_batch)\n","            y_label = np.array(y_label)\n","            y_label = torch.tensor(y_label, dtype=torch.float32).to(device)\n","\n","            bincount_list = torch.bincount(batch.batch).tolist()\n","            if any(bincount_list): #checks if any values are not zero.\n","                batch_p = torch.cat([torch.full((num_nodes_graph_i,), i, device=device) for i, num_nodes_graph_i in enumerate(bincount_list)])\n","                batch_p = batch_p.to(device)\n","            else:\n","                # Handle the case where the list is empty. For example, create an empty tensor or raise an error.\n","                print(\"Warning: bincount_list is empty. Creating an empty tensor.\")\n","                batch_p = torch.empty(0, dtype=torch.long, device=device) # create empty tensor.\n","\n","            # Forward pass\n","            output = model(x, edge_index, hash_encoded, batch_p)\n","            count_batch += 1\n","\n","            if output.shape != y_label.shape:\n","                print(f\"Warning: output shape {output.shape} and y_label shape {y_label.shape} do not match.\")\n","                break\n","\n","            loss = F.binary_cross_entropy_with_logits(output, y_label.float())\n","            train_loss += loss.item()\n","\n","            loss.backward(retain_graph=True)\n","            optimizer.step()\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","        #avg_train_loss = train_loss / len(train_dataloader)\n","        #print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}\")\n","\n","    # save model trained\n","    torch.save(model.state_dict(), model_save_file)\n","\n","def validate_model_perf(validation_dataloader, val_hash, batch_size):\n","    if os.path.exists(model_save_file):\n","        model.load_state_dict(torch.load(model_save_file, weights_only=True))\n","\n","    model.eval() #set the model to evaluation mode.\n","    all_true_label = []\n","    all_pred_label = []\n","    #hash_v = []\n","\n","    count_batch = 0\n","    with torch.no_grad():\n","        for batch in validation_dataloader:\n","            x = batch.x.to(device)\n","            edge_index = batch.edge_index.to(device)\n","            hash_encoded = batch.hash_encoded.to(device)\n","\n","            list_hash_batch = val_hash[count_batch*batch_size:(count_batch+1)*batch_size]\n","            y_label = get_metadata_from_hash(list_hash_batch)\n","            y_label = np.array(y_label)\n","            y_label = torch.tensor(y_label, dtype=torch.float32).to(device)\n","\n","            bincount_list = torch.bincount(batch.batch).tolist()\n","            if any(bincount_list): #checks if any values are not zero.\n","                batch_p = torch.cat([torch.full((num_nodes_graph_i,), i, device=device) for i, num_nodes_graph_i in enumerate(bincount_list)])\n","                batch_p = batch_p.to(device)\n","            else:\n","                # Handle the case where the list is empty. For example, create an empty tensor or raise an error.\n","                print(\"Warning: bincount_list is empty. Creating an empty tensor.\")\n","                batch_p = torch.empty(0, dtype=torch.long, device=device) # create empty tensor.\n","\n","            # Forward pass\n","            output = model(x, edge_index, hash_encoded, batch_p)\n","            count_batch += 1\n","\n","            if output.shape != y_label.shape:\n","                print(f\"Warning: output shape {output.shape} and y_label shape {y_label.shape} do not match.\")\n","                break\n","\n","            predicted_labels_prob = torch.sigmoid(output)\n","            prediction_labels = (predicted_labels_prob > 0.5).int()\n","            all_true_label.append(y_label.cpu())\n","            all_pred_label.append(prediction_labels.cpu())\n","            #hash_v.append(list_hash_batch)\n","\n","    true_labels_tensor = torch.cat(all_true_label, dim=0) # Concatenate along dimension 0\n","    pred_labels_tensor = torch.cat(all_pred_label, dim=0) # Concatenate along dimension 0\n","\n","    return pred_labels_tensor, true_labels_tensor\n","\n","def run_files_in_batches(full_file_paths, batch_files_size=50, mode='train'):\n","    \"\"\"\n","    Processes files in batches for tokenization and model training/evaluation in a single loop.\n","    Args:\n","        full_file_paths (list): List of full file paths to process.\n","        batch_files_size (int): Number of files to process in each batch for tokenization.\n","        batch_data_size (int): Batch size for the DataLoader during training/evaluation.\n","        num_feature_dim (int, optional): Dimension of node features. Defaults to None.\n","        mode (str): 'train' or other mode (e.g., 'eval'). Defaults to 'train'.\n","        epochs (int): Number of training epochs per batch (if mode is 'train'). Defaults to 3.\n","        tokenizer: Tokenizer object with methods like get_tokens_and_counts and fit_from_counts.\n","        process_batch (callable): Function to process a batch of file paths and return a list of graph-like objects.\n","        train_model (callable): Function to train the model with a DataLoader and other info.\n","    \"\"\"\n","    print(f\"There are {len(full_file_paths)} files for {mode}\")\n","\n","    num_files = len(full_file_paths)\n","    nb_batch = (num_files // batch_files_size) + 1\n","\n","    hash_v = []\n","    hash_t = []\n","    all_true_label = []\n","    all_pred_label = []\n","\n","    all_counts = {\n","        'node_types': [],\n","        'operations': [],\n","        'registers': [],\n","        'memory_patterns': [],\n","        'immediates': [],\n","        'unique_hashes': [],\n","    }\n","\n","    print(\"**** Tokenization and Dataset Processing & Training\")\n","    for i in range(0, num_files, batch_files_size):\n","        batch_files = full_file_paths[i:i + batch_files_size]\n","        batch_num = i // batch_files_size + 1\n","        print(f\"Processing batch {batch_num}/{nb_batch}: {len(batch_files)} files\")\n","\n","        batch_graph_list = process_batch(batch_files)\n","        if not batch_graph_list:\n","            print(\"graph list is empty for this batch\")\n","            continue\n","\n","        # Tokenization for the current batch\n","        tokens = tokenizer.get_tokens_and_counts(batch_graph_list)\n","        for key in all_counts:\n","            if key in tokens:\n","                all_counts[key].extend(tokens[key])\n","        tokenizer.fit_from_counts(all_counts)\n","        # Create Dataset and DataLoader for the current batch\n","        if tokenizer and num_feature_dim is not None:\n","            dataset = AssemblyGraphDataset(batch_graph_list, tokenizer, node_feature_dim=num_feature_dim)\n","            curr_dataloader = DataLoader(dataset, batch_size=batch_data_size, shuffle=False)\n","            list_of_hash = [graph['name'] for graph in batch_graph_list]\n","\n","            # Training or other processing for the current batch\n","            if mode == 'train' and train_model:\n","                print(f\"**** Training on batch {batch_num}/{nb_batch}\")\n","                train_model(curr_dataloader, list_of_hash, batch_data_size, epochs=epochs)\n","                hash_t.extend(list_of_hash)\n","            # Add logic for other modes (e.g., 'eval') here if needed\n","            else:\n","                pred_labels, true_labels = validate_model_perf(curr_dataloader, list_of_hash, batch_data_size)\n","                all_true_label.append(true_labels.cpu())\n","                all_pred_label.append(pred_labels.cpu())\n","                hash_v.append(list_of_hash)\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    # Final fitting of the tokenizer after processing all batches\n","    if all_counts:\n","        print(\"**** Finalizing Tokenizer Vocabulary\")\n","        tokenizer.fit_from_counts(all_counts)\n","\n","    #print(\"**** Processing Complete\")\n","    # save all labels as tensor to return if mode= 'validation'\n","    if mode == 'validation':\n","        all_true_label_tensor = torch.cat(all_true_label).cpu().numpy()\n","        all_pred_label_tensor = torch.cat(all_pred_label).cpu().numpy()\n","\n","        return all_pred_label_tensor, all_true_label_tensor, hash_v\n","    elif mode == 'train':\n","        return hash_t\n"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1012311,"status":"ok","timestamp":1742996849138,"user":{"displayName":"jean-charles Monceau","userId":"11688387581777078781"},"user_tz":-60},"id":"avU1v3vVtSu-","outputId":"6997934b-0488-425c-8002-82e6e68dcf47"},"outputs":[{"output_type":"stream","name":"stdout","text":["========== batch: rep_0 ========== \n","Number of files with error: 0\n","There are 51 files for validation\n","**** Tokenization and Dataset Processing & Training\n","Processing batch 1/26: 2 files\n","Processing batch 2/26: 2 files\n","Processing batch 3/26: 2 files\n","Processing batch 4/26: 2 files\n","Processing batch 5/26: 2 files\n","Processing batch 6/26: 2 files\n","Processing batch 7/26: 2 files\n","Processing batch 8/26: 2 files\n","Processing batch 9/26: 2 files\n","Processing batch 10/26: 2 files\n","Processing batch 11/26: 2 files\n","Processing batch 12/26: 2 files\n","Processing batch 13/26: 2 files\n","Processing batch 14/26: 2 files\n","Processing batch 15/26: 2 files\n","Processing batch 16/26: 2 files\n","Processing batch 17/26: 2 files\n","Processing batch 18/26: 2 files\n","Processing batch 19/26: 2 files\n","Processing batch 20/26: 2 files\n","Processing batch 21/26: 2 files\n","Processing batch 22/26: 2 files\n","Processing batch 23/26: 2 files\n","Processing batch 24/26: 2 files\n","Processing batch 25/26: 2 files\n","Processing batch 26/26: 1 files\n","**** Finalizing Tokenizer Vocabulary\n","**** F1 score: 42.31 \n","\n","========== batch: rep_500 ========== \n","size 358759.218 /content/drive/MyDrive/Sorbonne_Data_challenge/folder_training_set/cf0a36610c4e55d8e12493a810cabd97b236c4966f0e0e2d53f44b24edd402ae.json\n","meta  /content/drive/MyDrive/Sorbonne_Data_challenge/folder_training_set/.json\n","Number of files with error: 2\n","There are 39 files for validation\n","**** Tokenization and Dataset Processing & Training\n","Processing batch 1/20: 2 files\n","Processing batch 2/20: 2 files\n","Processing batch 3/20: 2 files\n","Processing batch 4/20: 2 files\n","Processing batch 5/20: 2 files\n","Processing batch 6/20: 2 files\n","Processing batch 7/20: 2 files\n","Processing batch 8/20: 2 files\n","Processing batch 9/20: 2 files\n","Processing batch 10/20: 2 files\n","Processing batch 11/20: 2 files\n","Processing batch 12/20: 2 files\n","Processing batch 13/20: 2 files\n","Processing batch 14/20: 2 files\n","Processing batch 15/20: 2 files\n","Processing batch 16/20: 2 files\n","Processing batch 17/20: 2 files\n","Processing batch 18/20: 2 files\n","Processing batch 19/20: 2 files\n","Processing batch 20/20: 1 files\n","**** Finalizing Tokenizer Vocabulary\n","**** F1 score: 45.31 \n","\n"]}],"source":["###############################################################\n","# Main init and training sequence\n","###############################################################\n","# Batch params\n","batch_data_size = 1\n","batch_files_size = 2\n","num_feature_dim = 15\n","epochs =  5\n","\n","# Initialize model\n","tokenizer = HierarchicalAssemblyTokenizer()\n","model = AssemblyGAT(node_feature_dim=num_feature_dim, hidden_dim=64, output_dim=453)\n","model = model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n","\n","batch_curr = 'rep_0'\n","for i in range(0, 600, 500):\n","  batch_curr = f'rep_{i}'\n","  print(f\"========== batch: {batch_curr} ========== \")\n","  list_train, list_val, list_err = process_graph_directory(training_path_dir, val_size=0.01, rep_batch=batch_curr, max_file=0)\n","\n","  # validate\n","  all_pred_label_tensor, all_true_label_tensor, hash_v = run_files_in_batches(list_val, batch_files_size=batch_files_size, mode='validation')\n","  f1_macro = f1_score(all_true_label_tensor, all_pred_label_tensor, average='macro', zero_division=1)\n","  print(f\"**** F1 score: {f1_macro*100:.2f} \\n\")\n","\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"}},"nbformat":4,"nbformat_minor":0}